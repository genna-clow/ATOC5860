{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a86abc4-1cc3-4e2d-825c-ce0a8baa8b14",
   "metadata": {},
   "source": [
    "# ATOC 5860 Homework 1\n",
    "## Genevieve Clow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "308ae9af-65ac-4d18-aa25-49d650b7cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ae9334-5fb5-47b7-85b2-fc7fae220562",
   "metadata": {},
   "source": [
    "# 1) Basic Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e95e9f-4b69-48d4-a182-9af383eaccb3",
   "metadata": {},
   "source": [
    "## 1. a)\n",
    "\n",
    "*Bayes Theorem. Assume background rates of COVID are 90% negative, 10% positive\n",
    "AND COVID tests are accurate 80% of the time, but fail 20% of the time. Your friend goes\n",
    "and gets a COVID test. Your friend test negative. What is the probability that your friend\n",
    "is actually negative? Explain to your friend how you are using Bayes theorem to inform\n",
    "your thinking. Hint: Review Lecture #1 and the 1.2.2.2 of the Barnes Notes. (10 points)*\n",
    "\n",
    "**Barnes eq. 23**\n",
    "\n",
    "$$\n",
    "Pr(N|T) = \\frac{Pr(T|N)Pr(N)}{Pr(T|N)Pr(N)+Pr(T|P)Pr(P)}\n",
    "$$\n",
    "\n",
    "* Pr(N|T) = probability of being negative given a negative test result\n",
    "* Pr(T|N) = probability of an accurate test = 80%\n",
    "* Pr(T|P) = probability of an inaccurate test = 20%\n",
    "* Pr(N) = background rate of negative tests = 90%\n",
    "* Pr(P) = background rate of positive tests = 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ae8516f-c746-488f-8e24-4f5c40b74b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9729729729729729\n"
     ]
    }
   ],
   "source": [
    "pr_n_t = (0.8*0.9)/((0.8*0.9)+(0.2*0.1))\n",
    "print(pr_n_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd97abe-fb2d-40b2-bfa2-af1a79c5fa84",
   "metadata": {},
   "source": [
    "There is a 97% chance that your friend is actually negative, given their negative result. \n",
    "\n",
    "Using Bayes theorem, we can use our knowledge of background COVID rates to improve our interpretation of the test result. Without knowing the background rates, we would be 80% confident in the test result. However, given that the background rate is so low, we can be even more confident that it is a true negative. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96561d2-10f7-4ef3-95a9-db18f41d1f3a",
   "metadata": {},
   "source": [
    "## 1. b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9824d308-a610-4389-995e-bc16c8c438da",
   "metadata": {},
   "source": [
    "*Explain how to test whether a sample mean is significantly different than zero at the\n",
    "95% confidence level and the 99% confidence level. State each of the 5 steps in\n",
    "hypothesis testing that you are using. For step 4, calculate the specific critical value\n",
    "assuming a two-tailed test. Contrast your approach for a sample with 15 independent\n",
    "observations (N=15) and a sample 1000 independent observations (N=1000). (15 points)*\n",
    "\n",
    "We can determine how much the sample mean deviates from the population mean by calculating the z (large N) or t (small N) statistic. These values indicate the number of standard errors that our sample means lies from the population mean. To determine if the difference is statistically significant, we follow the steps below.\n",
    "\n",
    "Steps in Hypothesis Testing: \n",
    "1. State the signicance level: \n",
    "    - For the 95% confidence level: alpha = 0.05 \n",
    "    - For the 99% confidence level: alpha = 0.01\n",
    "2. State the null hypothesis (H0) and the alternative (H1)\n",
    "    - H0 = The (standardized) sample mean is equal to zero\n",
    "    - H1 = The sample mean is not equal to zero\n",
    "3. State the statistic to be used, and the assumptions required to use it\n",
    "    - For N = 15: use the t-statistic becuase we have a small sample size (<30)\n",
    "    - For N = 1000: use the z-statistic becuase we have a large sample size \n",
    "    - Assumptions: the data variables are normally distributed and the samples are independent. \n",
    "4. State the critical region\n",
    "    - For the 95% confidence level: tcrit = 2.14, zcrit = 1.96\n",
    "    - For the 99% confidence level: tcrit = 2.97, zcrit = 2.57\n",
    "5. Evaluate the statistic and state the conclusion\n",
    "    - Calculate the t and z statistics using the equations below\n",
    "    - If abs(t) > tcrit or abs(z) > zcrit, then we can reject the null hypothesis. This means that there is 5% (or 1%) probability of getting the sample mean by chance given the population. \n",
    "\n",
    "    \\begin{align}\n",
    "    z = \\frac{\\bar{X} - \\mu}{\\frac{\\sigma}{\\sqrt{N}}}\n",
    "    \\end{align}\n",
    "\n",
    "    - Where $\\bar{X}$ = sample mean, $\\sigma$ = population standard deviation, $\\mu$ = population mean, N = sample size\n",
    "\n",
    "    $$\n",
    "    t = \\frac{\\bar{x} - \\mu}{\\frac{s}{\\sqrt{N-1}}}\n",
    "    $$\n",
    "\n",
    "    - Where $\\bar{x}$ = sample mean, s = sample standard deviation, $\\mu$ = population mean, N = sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83c5c4e1-2f67-4cc3-8a2e-8bb02d30a46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence level\n",
      "t-stat critical value (N = 15): 2.1448\n",
      "z-stat critical value (N = 1000): 1.96\n"
     ]
    }
   ],
   "source": [
    "print('95% confidence level')\n",
    "alpha = 0.05 \n",
    "# python calculates lower tail probability, we want two-sided test\n",
    "p = (1-alpha/2)\n",
    "\n",
    "# t-stat\n",
    "# df = 15 -1\n",
    "tcrit = stats.t.ppf(p, 14) \n",
    "print('t-stat critical value (N = 15):', round(tcrit,4))\n",
    "\n",
    "# z-stat\n",
    "zcrit = stats.norm.ppf(p)\n",
    "print('z-stat critical value (N = 1000):', round(zcrit,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb7068e1-589a-4123-998d-9fea0842e871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99% confidence level\n",
      "t-stat critical value (N = 15): 2.9768\n",
      "z-stat critical value (N = 1000): 2.5758\n"
     ]
    }
   ],
   "source": [
    "print('99% confidence level')\n",
    "alpha = 0.01 \n",
    "# python calculates lower tail probability, we want two-sided test\n",
    "p = (1-alpha/2)\n",
    "\n",
    "# t-stat\n",
    "# df = 15 -1\n",
    "tcrit = stats.t.ppf(p, 14)\n",
    "print('t-stat critical value (N = 15):', round(tcrit,4))\n",
    "\n",
    "# z-stat\n",
    "zcrit = stats.norm.ppf(p)\n",
    "print('z-stat critical value (N = 1000):', round(zcrit,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027fe0e7-d76e-4c86-972a-ea2fef95ed4a",
   "metadata": {},
   "source": [
    "## 1. c)  \n",
    "\n",
    "*Design your own homework problem to compare two sample means using data of your\n",
    "own choice. In other words, test whether two sample means are statistically different.\n",
    "Follow all five steps of hypothesis testing. Hint: See page 26 of Barnes notes for an\n",
    "example. (15 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd70e4b-e31b-4c61-8587-0e43a82364d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compare the global mean of surface chlorophyll derived from two satellie emulators (using MODIS and ISCCP clouds)\n",
    "\n",
    "Since chlorophyll is log-normally distributed, I attempted to apply the central limit theorem. Instead of using the raw chlorophyll values (daily), I first took the annual global average. Then, I compared the means of the annual data. Unfortunately, we only have 30 years of data to work with, so this is a small sample size and the central limit theorem may not apply.\n",
    "\n",
    "Hypothesis testing: \n",
    "1. State the signicance level: 95% (alpha = 0.05)\n",
    "2. State the null hypothesis H0 and the alternative H1\n",
    "- H0 = The global mean of the two chlorophyll samples are equal.\n",
    "- H1 = The global mean of the two chlorophyll samples are NOT equal.\n",
    "3. State the statistic to be used, and the assumptions required to use it\n",
    "- I will use a two-sided t-test. Since I am using annual means, the small sample sizes are small (30). I am assuming that the two samples are drawn from normal distributions with equal standard deviations. \n",
    "4. State the critical region\n",
    "- tcrit = 2.045 (if t > tcrit, reject the null hypothesis)\n",
    "5. Evaluate the statistic and state the conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c113b3b3-a254-46da-852e-13d825771418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.045229642132703\n"
     ]
    }
   ],
   "source": [
    "# Determine the critical value\n",
    "# We have 30 years of data for each sample\n",
    "# N1 = N2 = 30\n",
    "N = 30 \n",
    "df = N - 1 \n",
    "tcrit = stats.t.ppf(0.975,df)\n",
    "print(tcrit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32985cc4-35dc-4851-88d0-7fd6ccfdf6c7",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9040e3c4-9c6b-428c-9896-8c8d1ffe3bf7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/glade/scratch/gclow/archive/b.e22.B1850.f09_g17.cosp_chlor_30yr/ocn/hist/b.e22.B1850.f09_g17.cosp_chlor_30yr.pop.h.nday1.0001-01-01.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/miniconda3/envs/data_analysis/lib/python3.9/site-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36m_acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                 \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/data_analysis/lib/python3.9/site-packages/xarray/backends/lru_cache.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: [<function _open_scipy_netcdf at 0x7ff342665c10>, ('/glade/scratch/gclow/archive/b.e22.B1850.f09_g17.cosp_chlor_30yr/ocn/hist/b.e22.B1850.f09_g17.cosp_chlor_30yr.pop.h.nday1.0001-01-01.nc',), 'r', (('mmap', None), ('version', 2)), '73fdcc15-7b84-430f-a27d-bb81b590c926']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jf/gvhmh84s2cb7nsfpkxnpw_m80000gn/T/ipykernel_6570/2744096655.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTAREA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/glade/scratch/gclow/archive/b.e22.B1850.f09_g17.cosp_chlor_30yr/ocn/hist/b.e22.B1850.f09_g17.cosp_chlor_30yr.pop.h.nday1.0001-01-01.nc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTAREA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/glade/scratch/gclow/archive/b.e22.B1850.f09_g17.cosp_chlor_30yr/ocn/daily/b.e22.B1850.f09_g17.cosp_chlor_30yr.pop.h.ecosys.nday1.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m data = xr.open_mfdataset(base+'*.nc', concat_dim=\"time\", parallel = True, chunks = {'time':120},\n",
      "\u001b[0;32m~/opt/miniconda3/envs/data_analysis/lib/python3.9/site-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0moverwrite_encoded_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"overwrite_encoded_chunks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m     backend_ds = backend.open_dataset(\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mdrop_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_variables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/data_analysis/lib/python3.9/site-packages/xarray/backends/scipy_.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, mode, format, group, mmap, lock)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mstore_entrypoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStoreBackendEntrypoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mclose_on_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             ds = store_entrypoint.open_dataset(\n\u001b[0m\u001b[1;32m    304\u001b[0m                 \u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mmask_and_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_and_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/data_analysis/lib/python3.9/site-packages/xarray/backends/store.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(self, store, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mdecode_timedelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     ):\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mvars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/data_analysis/lib/python3.9/site-packages/xarray/backends/common.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \"\"\"\n\u001b[1;32m    127\u001b[0m         variables = FrozenDict(\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0m_decode_variable_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         )\n\u001b[1;32m    130\u001b[0m         \u001b[0mattributes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrozenDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/data_analysis/lib/python3.9/site-packages/xarray/backends/scipy_.py\u001b[0m in \u001b[0;36mget_variables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         return FrozenDict(\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_store_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         )\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/data_analysis/lib/python3.9/site-packages/xarray/backends/scipy_.py\u001b[0m in \u001b[0;36mds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen_store_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/data_analysis/lib/python3.9/site-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36macquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mAn\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0mby\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \"\"\"\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_acquire_with_cache_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneeds_lock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/data_analysis/lib/python3.9/site-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36m_acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    213\u001b[0m                     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                 \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                     \u001b[0;31m# ensure file doesn't get overridden when opened again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/data_analysis/lib/python3.9/site-packages/xarray/backends/scipy_.py\u001b[0m in \u001b[0;36m_open_scipy_netcdf\u001b[0;34m(filename, mode, mmap, version)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetcdf_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# netcdf3 message is obscure in this case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0merrmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/data_analysis/lib/python3.9/site-packages/scipy/io/netcdf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, mmap, version, maskandscale)\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0momode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'r+'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%sb'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0momode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmmap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0;31m# Mmapped files on PyPy cannot be usually closed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/glade/scratch/gclow/archive/b.e22.B1850.f09_g17.cosp_chlor_30yr/ocn/hist/b.e22.B1850.f09_g17.cosp_chlor_30yr.pop.h.nday1.0001-01-01.nc'"
     ]
    }
   ],
   "source": [
    "TAREA = xr.open_dataset('/glade/scratch/gclow/archive/b.e22.B1850.f09_g17.cosp_chlor_30yr/ocn/hist/b.e22.B1850.f09_g17.cosp_chlor_30yr.pop.h.nday1.0001-01-01.nc').TAREA\n",
    "\n",
    "base = '/glade/scratch/gclow/archive/b.e22.B1850.f09_g17.cosp_chlor_30yr/ocn/daily/b.e22.B1850.f09_g17.cosp_chlor_30yr.pop.h.ecosys.nday1.'\n",
    "\n",
    "data = xr.open_mfdataset(base+'*.nc', concat_dim=\"time\", parallel = True, chunks = {'time':120},\n",
    "                              data_vars='minimal', compat='override', \n",
    "                              coords='minimal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfed290-8a14-406c-9937-fdd39c9669b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Calculate weighted global mean for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6135b4-b4d8-4481-bb01-e884025aecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "isccp_global_mean = ((data.totChl_isccp*TAREA).groupby('time.year').sum(dim = ['time','nlat','nlon'])/(data.totChl_isccp_wgt*TAREA).groupby('time.year').sum(dim = ['time','nlat','nlon'])).compute()\n",
    "modis_global_mean = ((data.totChl_modis*TAREA).groupby('time.year').sum(dim = ['time','nlat','nlon'])/(data.totChl_modis_wgt*TAREA).groupby('time.year').sum(dim = ['time','nlat','nlon'])).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33565093-35c4-4a6e-a206-dfe03e87ed27",
   "metadata": {},
   "outputs": [],
   "source": [
    "isccp_mean = isccp_global_mean.mean().data\n",
    "isccp_std = isccp_global_mean.std().data\n",
    "isccp_var = isccp_global_mean.var().data\n",
    "\n",
    "print('ISCCP Mean:',isccp_mean)\n",
    "print('ISCCP Standard Dev.:',isccp_std)\n",
    "xr.plot.hist(isccp_global_mean);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f84dbf-b353-4209-886e-8513da198f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modis_mean = modis_global_mean.mean().data\n",
    "modis_std = modis_global_mean.std().data\n",
    "modis_var = modis_global_mean.var().data\n",
    "\n",
    "print('MODIS Mean:',modis_mean)\n",
    "print('MODIS Standard Dev.:',modis_std)\n",
    "xr.plot.hist(modis_global_mean);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d65b39c-cd33-4b68-b7c9-28549dce499d",
   "metadata": {},
   "source": [
    "The means are not normally distributed. Therefore, we may be violating an important assumption in our test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2ed3dc-13a1-4abe-99aa-cb1b0711f49c",
   "metadata": {},
   "source": [
    "### Calculate the t statistic\n",
    "**Barnes Eq. 101**\n",
    "\n",
    "$t = \\frac{\\bar{x_{1}} - \\bar{x_{2}}}{\\hat{\\sigma}\\sqrt{\\frac{1}{N_{1}} + \\frac{1}{N_{2}}}}$\n",
    "\n",
    "where\n",
    "$\\hat{\\sigma} = \\sqrt{\\frac{N_{1}s_{1}^2+N_{2}s_{2}^2}{N_{1}+N_{2}-2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1f6440-8d19-44d2-8749-054d00589a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = np.sqrt((N*isccp_var + N*modis_var)/(N+N-2))\n",
    "print(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d90b7f-b46b-4855-9587-08d5abfd5205",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (isccp_mean - modis_mean)/(sigma*np.sqrt((1/N)+(1/N)))\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a64bfae-ed60-4581-b278-f1b6b83ff71a",
   "metadata": {},
   "source": [
    "Conclusion: Since t > tcrit, we can reject the null hypothesis. This means that there is a 95% chance that the difference in means did not occur by chance. However, I am not super confident in this result becuase the sample size is small and the variables are not normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd44186-a1d2-44c5-bd21-94207d8af20d",
   "metadata": {},
   "source": [
    "## 1. d)\n",
    "\n",
    "*Design your own homework problem to place 95% confidence intervals on the mean\n",
    "value of a data variable of your choice. Use the non-standardized variable. Hint: See\n",
    "Barnes notes on Confidence Intervals.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd92dde-7ead-441c-b935-f6c48f8f195c",
   "metadata": {},
   "source": [
    "I calculated the confidence intervals on the simulated chlorophyll observations (derived from ISCCP clouds) using the equation below.\n",
    "\n",
    "**Barnes Eq. 100** \n",
    "\n",
    "$$\n",
    "\\mu = \\bar{x} \\pm t_{c}\\frac{s}{\\sqrt{N-1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890dc53d-715c-480c-b090-344b6076d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate t_crit\n",
    "N = 30 \n",
    "df = N - 1 \n",
    "tcrit = stats.t.ppf(0.975,df)\n",
    "print(tcrit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0820d3-bdea-4f1c-908e-caf6034cddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate upper and lower limits\n",
    "diff = tcrit*(isccp_std/np.sqrt(N-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1bce21-4583-465b-9581-58674b62e2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(isccp_mean-diff,3), '<= \\u03BC <=', round(isccp_mean+diff,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e661519-6a26-47e5-bcd4-d3a69391dfa5",
   "metadata": {},
   "source": [
    "## 1. e)\n",
    "\n",
    "*The F-statistic is used to compare two sample standard deviations. Design your own\n",
    "homework problem to compare two sample standard deviations and assess if they are\n",
    "different at the 95% confidence interval. Hint: See page 38 of the Barnes notes. Note:\n",
    "When calculating the f-statistic Barnes Chapter 1 Equation (122), the larger variance\n",
    "should always be on top (numerator) and the smaller variance should always be on\n",
    "bottom (denominator). i.e., F = Larger variance / Smaller variance. (10 points)*\n",
    "\n",
    "The F-statistic is used to compare two sample standard deviations. Design your own\n",
    "homework problem to compare two sample standard deviations and assess if they are\n",
    "different at the 95% confidence interval. Hint: See page 38 of the Barnes notes. Note:\n",
    "When calculating the f-statistic Barnes Chapter 1 Equation (122), the larger variance\n",
    "should always be on top (numerator) and the smaller variance should always be on\n",
    "bottom (denominator). i.e., F = Larger variance / Smaller variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3329ec9-a10c-4a90-80b9-85ba409f53ee",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1) State significance level. alpha=0.05; 95% confidence\n",
    "2) Null Hypothesis = The standard deviation for both chlorophyll samples are the same.\n",
    "3) We will use the f-statistic. We will assume data1 and data2 come from normal populations having the same true variance.\n",
    "4) Find critical value to exceed to reject the null hypothsis (fcrit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf6a53b-311b-453e-8bf1-457df7ccdfd3",
   "metadata": {},
   "source": [
    "**Barnes Eq. 122** \n",
    "\n",
    "$$\n",
    "F = \\frac{s_{1}^2}{s_{2}^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244a8f09-8472-4b38-8f89-97f522be822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 0.975 because this function calculates the lower-tail probability\n",
    "fcrit = stats.f.ppf(q = 0.975, dfn = N-1, dfd = N-1)\n",
    "print(fcrit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97545241-ea7e-43bb-b288-4fa5b40cdda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = isccp_var/modis_var\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38637fe-4bc1-4ef1-a31d-526cc237cb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(f) > fcrit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fb1fc0-6783-43da-ab17-d93cf5b47f9f",
   "metadata": {},
   "source": [
    "We cannot reject our null hypothesis that the two samples have different variances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68907624-a352-44cf-a623-d7e6ef4512f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2) Bootstrapping\n",
    "\n",
    "*Compare composite-averages using t/z tests and bootstrapping. Note: coding is required\n",
    "for this problem. Please use python Jupyter notebooks. It will be helpful follow the ipython\n",
    "notebook examples introduced in Application Lab #1 and in lectures. (40 points)\n",
    "Your friend living in Fort Collins tells you that the air pressure is anomalous when there is\n",
    "measurable precipitation (greater than or equal to 0.01 inches). To test your friends’\n",
    "hypothesis, use hourly observations from Fort Collins in 2014. The data include both the\n",
    "precipitation amount in units of inches and pressure in units of hPa at hourly frequency. The\n",
    "data file is called homework1_data.csv.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35cdd0a-5df9-40f9-bdeb-924db69a4cc8",
   "metadata": {},
   "source": [
    "### Load data and make exploratory plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af58a538-031e-4bc4-bd92-40a52192a7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('homework1_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b758db6c-e2f7-4c27-8cf4-414dc2cb0032",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['P_hPa'].plot()\n",
    "plt.xlabel('Time (hr)');\n",
    "plt.ylabel('Pressure (hPA)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b95e60-86c7-4e90-a14a-7e7636756657",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data['P_hPa'])\n",
    "plt.xlabel('Pressure (hPa)');\n",
    "plt.ylabel('Count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c160fc2-7e0d-47d7-8720-e884e8bdee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['R_inches'].plot()\n",
    "plt.xlabel('Time (hr)');\n",
    "plt.ylabel('Rain (in)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22882f3e-6384-4cbb-b305-4e107f102b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data['R_inches'])\n",
    "plt.xlabel('Rain (in)');\n",
    "plt.ylabel('Count');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7490c477-2267-4a09-9dd0-d37b76887db4",
   "metadata": {},
   "source": [
    "## 2.a) \n",
    "*What was the average pressure in 2014? What was the average pressure when it\n",
    "rained? (10 points)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5950fe-0519-4f8b-97fe-edacdb287454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average pressure \n",
    "data['P_hPa'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffa2660-b355-4ab3-9296-be0797ac8cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average pressure when it rained\n",
    "data_rain = data[data['R_inches']>=0.01].copy()\n",
    "data_rain['P_hPa'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c84083a-ae86-4a9c-aa4f-e3c232b5485b",
   "metadata": {},
   "source": [
    "The average pressure in 2014 was 846.33 hPa. When it rained, the average pressure was 847.03 hPa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab638a07-58b1-438d-aa27-f47fcb7419fb",
   "metadata": {},
   "source": [
    "## 2.b)\n",
    "\n",
    "*Test your friends’ hypothesis by generating confidence intervals using both a t-statistic\n",
    "and a z-statistic. Is the average pressure different when it is raining? What is more\n",
    "appropriate to use as a statistical test – a t- or a z-statistic? Use 95% confidence interval.\n",
    "(15 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdbfa23-ec27-44ae-bc0b-cb8d4ae026ee",
   "metadata": {},
   "source": [
    "**For the t-test:** \n",
    "\n",
    "$$\n",
    "\\mu = \\bar{x} \\pm t_{c}\\frac{s}{\\sqrt{N-1}}\n",
    "$$\n",
    "\n",
    "**For the z-test:** \n",
    "\n",
    "$$\n",
    "\\mu = \\bar{x} \\pm z_{c}\\frac{s}{\\sqrt{N}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2811444d-cc8e-4614-95cc-0cde31d868ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = data_rain['P_hPa'].count()\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8f017b-e803-4468-9172-642868b4f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcrit = stats.t.ppf(0.975, N-1)\n",
    "zcrit = stats.norm.ppf(0.975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cd8b90-f8bf-4c59-8402-5fc3f86d854b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-stat\n",
    "low_lim = data_rain['P_hPa'].mean()-zcrit*(data_rain['P_hPa'].std()/np.sqrt(N))\n",
    "high_lim = data_rain['P_hPa'].mean()+zcrit*(data_rain['P_hPa'].std()/np.sqrt(N))\n",
    "print('z-stat confidence interval: ', round(low_lim,3), '-', round(high_lim,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d5840d-33cb-4455-90ad-41ee8750d840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-stat\n",
    "low_lim = data_rain['P_hPa'].mean()-tcrit*(data_rain['P_hPa'].std()/np.sqrt(N-1))\n",
    "high_lim = data_rain['P_hPa'].mean()+tcrit*(data_rain['P_hPa'].std()/np.sqrt(N-1))\n",
    "print('t-stat confidence interval: ', round(low_lim,3), '-', round(high_lim,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a1058f-0831-41ab-aa3e-cf4825d220d6",
   "metadata": {},
   "source": [
    "The mean of all data (846.332) lies outside of the 95% confidence range of the rainy data. The z-statistic and t-statistic are very similar in this case, so I would argue that either would be appropriate. This indicates that we have a large enough sample where sample size doesn't significantly change our results.\n",
    "\n",
    "However, I suspect that there is high auto-correlation in this dataset, so the true number of independent samples may be lower. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465a1bcb-e7e7-45d9-8065-18b9af20fe94",
   "metadata": {},
   "source": [
    "## 2.c)\n",
    "\n",
    "*Instead of the t/z-test – use bootstrap sampling to determine whether the local\n",
    "pressure is anomalously high during times when it is raining. How does your answer\n",
    "compare with your results using the t/z-test? (15 points)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df31b0-b18a-4981-bf15-68e1f3b0c2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_b = 1000\n",
    "\n",
    "## initialize array\n",
    "P_Bootstrap=np.empty((N_b,N))\n",
    "\n",
    "## loop over to fill in array with randomly selected values\n",
    "for i in range(N_b):\n",
    "    P_Bootstrap[i,:]=np.random.choice(data['P_hPa'],N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943440da-c3bd-455c-aa11-eeb1d6deb866",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the means of your randomly selected SWE values.\n",
    "P_Bootstrap_mean=np.mean(P_Bootstrap,axis=1)\n",
    "\n",
    "P_Bootstrap_mean_avg=np.mean(P_Bootstrap_mean)\n",
    "print('Mean:',P_Bootstrap_mean_avg)\n",
    "P_Bootstrap_mean_std=np.std(P_Bootstrap_mean)\n",
    "print('Standard Dev:',P_Bootstrap_mean_std)\n",
    "P_Bootstrap_mean_min=np.min(P_Bootstrap_mean)\n",
    "print('Min:', P_Bootstrap_mean_min)\n",
    "P_Bootstrap_mean_max=np.max(P_Bootstrap_mean)\n",
    "print('Max:', P_Bootstrap_mean_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e97049-0aa8-4972-b9f1-0ec049321053",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(P_Bootstrap_mean)\n",
    "plt.xlabel('Mean Pressure (hPa)');\n",
    "plt.ylabel('Count');\n",
    "plt.title('Bootstrapped Randomly Selected Mean Pressure Values');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a6ddb0-e8c3-4975-ad72-41494c264758",
   "metadata": {},
   "source": [
    "**Barnes eq. 83**\n",
    "\n",
    "$$\n",
    "z = \\frac{\\bar{\\chi} - \\mu}{\\frac{\\sigma}{\\sqrt{N}}}\n",
    "$$\n",
    "\n",
    "where \n",
    "- $\\bar{\\chi}$ = sample mean \n",
    "- $\\mu$ = population mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb93e272-d39c-4d79-91ae-7118b85aed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_N is 1 because we are comparing the sample mean to a distribution of means\n",
    "sample_N = 1\n",
    "sample_mean=data_rain['P_hPa'].mean() # rainy days only\n",
    "population_mean=np.mean(P_Bootstrap_mean)\n",
    "population_std=np.std(P_Bootstrap_mean)\n",
    "xstd=population_std/np.sqrt(sample_N)\n",
    "z =(sample_mean-population_mean)/xstd\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b275ff0-4d7f-4ab6-b462-7ba5678a4d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zcrit = stats.norm.ppf(0.975)\n",
    "print(zcrit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d28dc9-1cc1-4c1c-8b3d-efbe14c7707c",
   "metadata": {},
   "source": [
    "z > zcrit, so we can reject the null hypothesis. This is consistent with what we found previously. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
